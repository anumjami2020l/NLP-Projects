{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca97b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply Count</th>\n",
       "      <th>Supporter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obed Khan</td>\n",
       "      <td>Shah Rukh Khan sirf ek</td>\n",
       "      <td>2023-01-30T02:44:56Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shahrukh  khan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aasif Patel</td>\n",
       "      <td>Salman khan</td>\n",
       "      <td>2023-01-29T13:49:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salman Khan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V Shejule Status</td>\n",
       "      <td>Only Salman bhai&lt;br&gt;Bhot Hard Bhai✌</td>\n",
       "      <td>2023-01-28T17:53:55Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Salman Khan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avinash Tudu rushika</td>\n",
       "      <td>Bollywood ka sabse bada super star srk</td>\n",
       "      <td>2023-01-28T17:38:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shahrukh  khan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DexterDrubo Animations-</td>\n",
       "      <td>In India Salman Khan has bigger stardom than S...</td>\n",
       "      <td>2023-01-28T11:34:45Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shahrukh  khan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name                                            Comment  \\\n",
       "0                Obed Khan                             Shah Rukh Khan sirf ek   \n",
       "1              Aasif Patel                                        Salman khan   \n",
       "2         V Shejule Status                Only Salman bhai<br>Bhot Hard Bhai✌   \n",
       "3     Avinash Tudu rushika             Bollywood ka sabse bada super star srk   \n",
       "4  DexterDrubo Animations-  In India Salman Khan has bigger stardom than S...   \n",
       "\n",
       "                   Time  Likes  Reply Count       Supporter  \n",
       "0  2023-01-30T02:44:56Z      0            0  Shahrukh  khan  \n",
       "1  2023-01-29T13:49:48Z      0            0     Salman Khan  \n",
       "2  2023-01-28T17:53:55Z      0            0     Salman Khan  \n",
       "3  2023-01-28T17:38:39Z      0            0  Shahrukh  khan  \n",
       "4  2023-01-28T11:34:45Z      0            0  Shahrukh  khan  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Salman_Khan_VS_Sharuk_Khan - Sheet2.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7f46ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shahrukh  khan', 'salman khan', 'both', 'comment', 'sharukh khan',\n",
       "       'shahrukh khan', ' shahrukh khan', nan, 'comments', 'ssha',\n",
       "       'cooment', 'ssa', 'commets'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Supporter']=df['Supporter'].str.lower()\n",
    "df['Supporter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a16c3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salman khan       461\n",
       "sharukh khan      386\n",
       "comment            62\n",
       "shahrukh  khan     61\n",
       "both               20\n",
       "shahrukh khan       2\n",
       "comments            2\n",
       " shahrukh khan      1\n",
       "ssha                1\n",
       "cooment             1\n",
       "ssa                 1\n",
       "commets             1\n",
       "Name: Supporter, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Supporter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3178419",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1=df[df['Supporter'].str.contains(\"sharukh khan\", na=False)].index\n",
    "ind2=df[df['Supporter'].str.contains(\"shahrukh  khan\", na=False)].index\n",
    "ind3=df[df['Supporter'].str.contains(\" shahrukh khan\", na=False)].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8a5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ind1,'Supporter']=\"shahrukh khan\" \n",
    "df.loc[ind2,'Supporter']=\"shahrukh khan\"\n",
    "df.loc[ind3,'Supporter']=\"shahrukh khan\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378c8612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shahrukh khan', 'salman khan', 'both', 'comment', nan, 'comments',\n",
       "       'ssha', 'cooment', 'ssa', 'commets'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Supporter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a8e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=[\"shahrukh khan\",\"salman khan\"]\n",
    "drop_ind=df[~df['Supporter'].str.contains('|'.join(search), na=False)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdb14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_ind, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc414f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shahrukh khan', 'salman khan'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Supporter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc36fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "vocab_size = 100000\n",
    "max_length = 120\n",
    "embedding_dim = 16\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c0be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply Count</th>\n",
       "      <th>Supporter</th>\n",
       "      <th>encoded_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Obed Khan</td>\n",
       "      <td>Shah Rukh Khan sirf ek</td>\n",
       "      <td>2023-01-30T02:44:56Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shahrukh khan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aasif Patel</td>\n",
       "      <td>Salman khan</td>\n",
       "      <td>2023-01-29T13:49:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>salman khan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>V Shejule Status</td>\n",
       "      <td>Only Salman bhai&lt;br&gt;Bhot Hard Bhai✌</td>\n",
       "      <td>2023-01-28T17:53:55Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>salman khan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Avinash Tudu rushika</td>\n",
       "      <td>Bollywood ka sabse bada super star srk</td>\n",
       "      <td>2023-01-28T17:38:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shahrukh khan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DexterDrubo Animations-</td>\n",
       "      <td>In India Salman Khan has bigger stardom than S...</td>\n",
       "      <td>2023-01-28T11:34:45Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shahrukh khan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Name  \\\n",
       "0           0                Obed Khan   \n",
       "1           1              Aasif Patel   \n",
       "2           2         V Shejule Status   \n",
       "3           3     Avinash Tudu rushika   \n",
       "4           4  DexterDrubo Animations-   \n",
       "\n",
       "                                             Comment                  Time  \\\n",
       "0                             Shah Rukh Khan sirf ek  2023-01-30T02:44:56Z   \n",
       "1                                        Salman khan  2023-01-29T13:49:48Z   \n",
       "2                Only Salman bhai<br>Bhot Hard Bhai✌  2023-01-28T17:53:55Z   \n",
       "3             Bollywood ka sabse bada super star srk  2023-01-28T17:38:39Z   \n",
       "4  In India Salman Khan has bigger stardom than S...  2023-01-28T11:34:45Z   \n",
       "\n",
       "   Likes  Reply Count      Supporter  encoded_labels  \n",
       "0      0            0  shahrukh khan               1  \n",
       "1      0            0    salman khan               0  \n",
       "2      0            0    salman khan               0  \n",
       "3      0            0  shahrukh khan               1  \n",
       "4      0            0  shahrukh khan               1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "Supporter=df['Supporter']\n",
    "Supporter=np.array(Supporter).reshape(-1,1)\n",
    "\n",
    "\n",
    "df['encoded_labels']=''\n",
    "enc=le.fit_transform(Supporter)\n",
    "\n",
    "df['encoded_labels']=enc\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d0230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize the Tokenizer class\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# Generate the word index dictionary for the training sentences\n",
    "tokenizer.fit_on_texts(df[\"Comment\"])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Generate and pad the training sequences\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Comment\"])\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15e8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded,df[\"encoded_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ce50f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 120, 512)         420864    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 512)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613,761\n",
      "Trainable params: 613,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Setup the training parameters\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f15ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 8s 286ms/step - loss: 0.6948 - accuracy: 0.4788 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 6s 262ms/step - loss: 0.6944 - accuracy: 0.4890 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 6s 265ms/step - loss: 0.6948 - accuracy: 0.5154 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 6s 277ms/step - loss: 0.6925 - accuracy: 0.5168 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 8s 356ms/step - loss: 0.6917 - accuracy: 0.5212 - val_loss: 0.6907 - val_accuracy: 0.5439\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 7s 335ms/step - loss: 0.6290 - accuracy: 0.7028 - val_loss: 0.4062 - val_accuracy: 0.8509\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 7s 328ms/step - loss: 0.5043 - accuracy: 0.8023 - val_loss: 0.6202 - val_accuracy: 0.7149\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 7s 331ms/step - loss: 0.4310 - accuracy: 0.8404 - val_loss: 0.6053 - val_accuracy: 0.7149\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 7s 336ms/step - loss: 0.4009 - accuracy: 0.8668 - val_loss: 0.6188 - val_accuracy: 0.7456\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 8s 375ms/step - loss: 0.3534 - accuracy: 0.8829 - val_loss: 0.5673 - val_accuracy: 0.7544\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 8s 358ms/step - loss: 0.3390 - accuracy: 0.8946 - val_loss: 0.5771 - val_accuracy: 0.7500\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.2989 - accuracy: 0.9063 - val_loss: 0.6177 - val_accuracy: 0.7544\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.2819 - accuracy: 0.9195 - val_loss: 0.5357 - val_accuracy: 0.8026\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 8s 385ms/step - loss: 0.2547 - accuracy: 0.9312 - val_loss: 0.5639 - val_accuracy: 0.8114\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.2381 - accuracy: 0.9414 - val_loss: 0.5076 - val_accuracy: 0.8289\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 9s 395ms/step - loss: 0.2098 - accuracy: 0.9473 - val_loss: 0.5201 - val_accuracy: 0.8333\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.2050 - accuracy: 0.9502 - val_loss: 0.5513 - val_accuracy: 0.8202\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.1988 - accuracy: 0.9517 - val_loss: 0.5916 - val_accuracy: 0.7895\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 8s 368ms/step - loss: 0.1805 - accuracy: 0.9546 - val_loss: 0.7200 - val_accuracy: 0.8070\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 8s 354ms/step - loss: 0.1750 - accuracy: 0.9561 - val_loss: 0.5566 - val_accuracy: 0.8202\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 8s 375ms/step - loss: 0.1981 - accuracy: 0.9400 - val_loss: 0.6612 - val_accuracy: 0.8246\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.1623 - accuracy: 0.9649 - val_loss: 0.7061 - val_accuracy: 0.8114\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 8s 371ms/step - loss: 0.1608 - accuracy: 0.9605 - val_loss: 0.7803 - val_accuracy: 0.7895\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 8s 374ms/step - loss: 0.2195 - accuracy: 0.9312 - val_loss: 0.6085 - val_accuracy: 0.7807\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 8s 378ms/step - loss: 0.1829 - accuracy: 0.9444 - val_loss: 0.6228 - val_accuracy: 0.7939\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 9s 394ms/step - loss: 0.1443 - accuracy: 0.9531 - val_loss: 0.5855 - val_accuracy: 0.7807\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.1928 - accuracy: 0.9590 - val_loss: 0.7029 - val_accuracy: 0.7895\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.1567 - accuracy: 0.9590 - val_loss: 0.7076 - val_accuracy: 0.7895\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 8s 378ms/step - loss: 0.1463 - accuracy: 0.9663 - val_loss: 0.7841 - val_accuracy: 0.7895\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.1306 - accuracy: 0.9693 - val_loss: 0.8810 - val_accuracy: 0.7807\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 8s 383ms/step - loss: 0.1321 - accuracy: 0.9634 - val_loss: 0.8039 - val_accuracy: 0.8026\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.1116 - accuracy: 0.9751 - val_loss: 0.8439 - val_accuracy: 0.8026\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.1055 - accuracy: 0.9766 - val_loss: 0.7959 - val_accuracy: 0.8026\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.1016 - accuracy: 0.9780 - val_loss: 0.8232 - val_accuracy: 0.8026\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.1014 - accuracy: 0.9780 - val_loss: 0.8636 - val_accuracy: 0.8026\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0881 - accuracy: 0.9810 - val_loss: 0.8697 - val_accuracy: 0.8026\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 9s 385ms/step - loss: 0.0900 - accuracy: 0.9810 - val_loss: 0.8145 - val_accuracy: 0.8070\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0981 - accuracy: 0.9810 - val_loss: 0.8462 - val_accuracy: 0.8070\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 8s 384ms/step - loss: 0.0861 - accuracy: 0.9810 - val_loss: 0.9005 - val_accuracy: 0.8070\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.8536 - val_accuracy: 0.8070\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 9s 399ms/step - loss: 0.0897 - accuracy: 0.9810 - val_loss: 0.8270 - val_accuracy: 0.8114\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 9s 396ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.8931 - val_accuracy: 0.8114\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 8s 381ms/step - loss: 0.0908 - accuracy: 0.9824 - val_loss: 0.8163 - val_accuracy: 0.8158\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0832 - accuracy: 0.9810 - val_loss: 0.8865 - val_accuracy: 0.8114\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 9s 400ms/step - loss: 0.0881 - accuracy: 0.9810 - val_loss: 0.9362 - val_accuracy: 0.8114\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0799 - accuracy: 0.9824 - val_loss: 0.8890 - val_accuracy: 0.8158\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 8s 386ms/step - loss: 0.0993 - accuracy: 0.9810 - val_loss: 0.8737 - val_accuracy: 0.8070\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0977 - accuracy: 0.9766 - val_loss: 0.7991 - val_accuracy: 0.8114\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 9s 395ms/step - loss: 0.0974 - accuracy: 0.9751 - val_loss: 0.8423 - val_accuracy: 0.8026\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 9s 393ms/step - loss: 0.0891 - accuracy: 0.9824 - val_loss: 0.8052 - val_accuracy: 0.8070\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 8s 379ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 0.7518 - val_accuracy: 0.8114\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 8s 372ms/step - loss: 0.0838 - accuracy: 0.9810 - val_loss: 0.7946 - val_accuracy: 0.8246\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 8s 373ms/step - loss: 0.0907 - accuracy: 0.9839 - val_loss: 0.7909 - val_accuracy: 0.8202\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.0825 - accuracy: 0.9839 - val_loss: 0.7691 - val_accuracy: 0.8202\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 8s 382ms/step - loss: 0.0815 - accuracy: 0.9839 - val_loss: 0.7896 - val_accuracy: 0.8158\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0875 - accuracy: 0.9839 - val_loss: 0.7960 - val_accuracy: 0.8158\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0811 - accuracy: 0.9839 - val_loss: 0.7474 - val_accuracy: 0.8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0819 - accuracy: 0.9824 - val_loss: 0.7799 - val_accuracy: 0.8202\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0793 - accuracy: 0.9824 - val_loss: 0.7318 - val_accuracy: 0.8114\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 8s 374ms/step - loss: 0.0777 - accuracy: 0.9839 - val_loss: 0.7765 - val_accuracy: 0.8114\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 0.0793 - accuracy: 0.9839 - val_loss: 0.7595 - val_accuracy: 0.8114\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 0.0780 - accuracy: 0.9839 - val_loss: 0.8162 - val_accuracy: 0.8114\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 8s 360ms/step - loss: 0.0774 - accuracy: 0.9839 - val_loss: 0.8084 - val_accuracy: 0.8114\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 8s 357ms/step - loss: 0.0835 - accuracy: 0.9810 - val_loss: 0.8044 - val_accuracy: 0.7939\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 8s 375ms/step - loss: 0.0796 - accuracy: 0.9795 - val_loss: 0.8366 - val_accuracy: 0.7982\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.0922 - accuracy: 0.9839 - val_loss: 0.8996 - val_accuracy: 0.8070\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 8s 376ms/step - loss: 0.0873 - accuracy: 0.9780 - val_loss: 0.8930 - val_accuracy: 0.7895\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 8s 367ms/step - loss: 0.1010 - accuracy: 0.9736 - val_loss: 0.8367 - val_accuracy: 0.7851\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 8s 359ms/step - loss: 0.0758 - accuracy: 0.9824 - val_loss: 0.8284 - val_accuracy: 0.8026\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 8s 363ms/step - loss: 0.0696 - accuracy: 0.9854 - val_loss: 0.9686 - val_accuracy: 0.7939\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 8s 358ms/step - loss: 0.0745 - accuracy: 0.9839 - val_loss: 0.8441 - val_accuracy: 0.8026\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 0.0703 - accuracy: 0.9868 - val_loss: 0.8657 - val_accuracy: 0.8070\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 8s 366ms/step - loss: 0.0723 - accuracy: 0.9868 - val_loss: 0.8631 - val_accuracy: 0.7982\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 8s 367ms/step - loss: 0.0568 - accuracy: 0.9868 - val_loss: 0.9144 - val_accuracy: 0.7982\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 8s 360ms/step - loss: 0.0678 - accuracy: 0.9868 - val_loss: 0.8201 - val_accuracy: 0.8070\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 8s 367ms/step - loss: 0.0640 - accuracy: 0.9868 - val_loss: 0.8836 - val_accuracy: 0.8026\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 8s 368ms/step - loss: 0.0785 - accuracy: 0.9868 - val_loss: 0.8204 - val_accuracy: 0.8158\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 8s 372ms/step - loss: 0.0632 - accuracy: 0.9868 - val_loss: 0.8589 - val_accuracy: 0.8070\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 8s 383ms/step - loss: 0.0682 - accuracy: 0.9868 - val_loss: 0.8915 - val_accuracy: 0.8026\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 9s 399ms/step - loss: 0.0665 - accuracy: 0.9868 - val_loss: 0.9175 - val_accuracy: 0.8070\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0659 - accuracy: 0.9868 - val_loss: 0.9770 - val_accuracy: 0.7982\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0689 - accuracy: 0.9868 - val_loss: 0.8923 - val_accuracy: 0.7982\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0610 - accuracy: 0.9868 - val_loss: 1.0149 - val_accuracy: 0.8026\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0630 - accuracy: 0.9868 - val_loss: 0.9746 - val_accuracy: 0.7982\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0630 - accuracy: 0.9868 - val_loss: 0.9380 - val_accuracy: 0.8026\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0648 - accuracy: 0.9868 - val_loss: 0.9940 - val_accuracy: 0.8026\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 9s 400ms/step - loss: 0.1377 - accuracy: 0.9693 - val_loss: 1.5647 - val_accuracy: 0.7807\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 9s 393ms/step - loss: 0.1093 - accuracy: 0.9751 - val_loss: 0.9491 - val_accuracy: 0.8114\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0846 - accuracy: 0.9780 - val_loss: 0.8821 - val_accuracy: 0.8026\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0811 - accuracy: 0.9824 - val_loss: 0.8761 - val_accuracy: 0.7939\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 9s 416ms/step - loss: 0.0694 - accuracy: 0.9839 - val_loss: 0.9476 - val_accuracy: 0.8026\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0775 - accuracy: 0.9839 - val_loss: 0.8987 - val_accuracy: 0.8070\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 9s 418ms/step - loss: 0.0750 - accuracy: 0.9854 - val_loss: 0.9354 - val_accuracy: 0.7939\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.1076 - accuracy: 0.9707 - val_loss: 0.7920 - val_accuracy: 0.8158\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0870 - accuracy: 0.9780 - val_loss: 0.8050 - val_accuracy: 0.8158\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0774 - accuracy: 0.9824 - val_loss: 0.8574 - val_accuracy: 0.8158\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0665 - accuracy: 0.9868 - val_loss: 0.8626 - val_accuracy: 0.8114\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0685 - accuracy: 0.9868 - val_loss: 0.9283 - val_accuracy: 0.8026\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0719 - accuracy: 0.9868 - val_loss: 0.8425 - val_accuracy: 0.8114\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0696 - accuracy: 0.9868 - val_loss: 0.8442 - val_accuracy: 0.8158\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0672 - accuracy: 0.9868 - val_loss: 0.8641 - val_accuracy: 0.8114\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 9s 419ms/step - loss: 0.0652 - accuracy: 0.9868 - val_loss: 0.9105 - val_accuracy: 0.8114\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 8s 386ms/step - loss: 0.0742 - accuracy: 0.9868 - val_loss: 0.8694 - val_accuracy: 0.8114\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 9s 394ms/step - loss: 0.0708 - accuracy: 0.9868 - val_loss: 0.8411 - val_accuracy: 0.8026\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 8s 381ms/step - loss: 0.0656 - accuracy: 0.9868 - val_loss: 0.8930 - val_accuracy: 0.8026\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 8s 386ms/step - loss: 0.0675 - accuracy: 0.9868 - val_loss: 0.9262 - val_accuracy: 0.8114\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0683 - accuracy: 0.9868 - val_loss: 0.9194 - val_accuracy: 0.8026\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 9s 393ms/step - loss: 0.0679 - accuracy: 0.9868 - val_loss: 0.8829 - val_accuracy: 0.8070\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 8s 384ms/step - loss: 0.0637 - accuracy: 0.9868 - val_loss: 0.9165 - val_accuracy: 0.8070\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 8s 378ms/step - loss: 0.0714 - accuracy: 0.9868 - val_loss: 0.9406 - val_accuracy: 0.8070\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0662 - accuracy: 0.9868 - val_loss: 0.9713 - val_accuracy: 0.8026\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0692 - accuracy: 0.9868 - val_loss: 0.9738 - val_accuracy: 0.8070\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0724 - accuracy: 0.9868 - val_loss: 1.0187 - val_accuracy: 0.8114\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 8s 383ms/step - loss: 0.0690 - accuracy: 0.9868 - val_loss: 0.9741 - val_accuracy: 0.8070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0612 - accuracy: 0.9868 - val_loss: 0.9351 - val_accuracy: 0.8070\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 9s 386ms/step - loss: 0.0608 - accuracy: 0.9868 - val_loss: 0.9951 - val_accuracy: 0.8026\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 8s 382ms/step - loss: 0.0643 - accuracy: 0.9868 - val_loss: 1.0073 - val_accuracy: 0.8026\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 9s 386ms/step - loss: 0.0668 - accuracy: 0.9868 - val_loss: 1.0836 - val_accuracy: 0.8070\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 8s 382ms/step - loss: 0.0694 - accuracy: 0.9868 - val_loss: 0.8981 - val_accuracy: 0.8026\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0678 - accuracy: 0.9868 - val_loss: 0.9765 - val_accuracy: 0.7982\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0625 - accuracy: 0.9868 - val_loss: 1.0277 - val_accuracy: 0.8026\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0605 - accuracy: 0.9868 - val_loss: 1.0727 - val_accuracy: 0.7982\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 8s 383ms/step - loss: 0.0678 - accuracy: 0.9839 - val_loss: 1.0278 - val_accuracy: 0.7982\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.0607 - accuracy: 0.9868 - val_loss: 1.0510 - val_accuracy: 0.8026\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 8s 381ms/step - loss: 0.0732 - accuracy: 0.9839 - val_loss: 0.9565 - val_accuracy: 0.7763\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 9s 386ms/step - loss: 0.0904 - accuracy: 0.9766 - val_loss: 1.2122 - val_accuracy: 0.7588\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0786 - accuracy: 0.9824 - val_loss: 0.8752 - val_accuracy: 0.8070\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0624 - accuracy: 0.9868 - val_loss: 1.0122 - val_accuracy: 0.8026\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0629 - accuracy: 0.9868 - val_loss: 1.0606 - val_accuracy: 0.7982\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0622 - accuracy: 0.9868 - val_loss: 1.1175 - val_accuracy: 0.7982\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 9s 418ms/step - loss: 0.0678 - accuracy: 0.9868 - val_loss: 1.0873 - val_accuracy: 0.7982\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0617 - accuracy: 0.9868 - val_loss: 1.1031 - val_accuracy: 0.8070\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 9s 413ms/step - loss: 0.0566 - accuracy: 0.9868 - val_loss: 1.1387 - val_accuracy: 0.8026\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0647 - accuracy: 0.9868 - val_loss: 1.1094 - val_accuracy: 0.7939\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0643 - accuracy: 0.9868 - val_loss: 1.1006 - val_accuracy: 0.7939\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0650 - accuracy: 0.9868 - val_loss: 1.1775 - val_accuracy: 0.7982\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0604 - accuracy: 0.9868 - val_loss: 1.0964 - val_accuracy: 0.7982\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 9s 393ms/step - loss: 0.0621 - accuracy: 0.9868 - val_loss: 1.1380 - val_accuracy: 0.8070\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 9s 396ms/step - loss: 0.0675 - accuracy: 0.9868 - val_loss: 1.1792 - val_accuracy: 0.7982\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0602 - accuracy: 0.9868 - val_loss: 1.2765 - val_accuracy: 0.7939\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0615 - accuracy: 0.9868 - val_loss: 1.2452 - val_accuracy: 0.7982\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 9s 397ms/step - loss: 0.0674 - accuracy: 0.9868 - val_loss: 1.2611 - val_accuracy: 0.7982\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0600 - accuracy: 0.9868 - val_loss: 1.3055 - val_accuracy: 0.7982\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0569 - accuracy: 0.9868 - val_loss: 1.3617 - val_accuracy: 0.7939\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.0631 - accuracy: 0.9868 - val_loss: 1.4566 - val_accuracy: 0.7982\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0657 - accuracy: 0.9868 - val_loss: 1.1583 - val_accuracy: 0.8070\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0636 - accuracy: 0.9854 - val_loss: 1.4102 - val_accuracy: 0.7939\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0575 - accuracy: 0.9868 - val_loss: 1.3994 - val_accuracy: 0.7939\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0593 - accuracy: 0.9868 - val_loss: 1.4574 - val_accuracy: 0.7895\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.0620 - accuracy: 0.9868 - val_loss: 1.4898 - val_accuracy: 0.7939\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0580 - accuracy: 0.9868 - val_loss: 1.4571 - val_accuracy: 0.7982\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0709 - accuracy: 0.9780 - val_loss: 1.3023 - val_accuracy: 0.8202\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 9s 393ms/step - loss: 0.0770 - accuracy: 0.9810 - val_loss: 1.1744 - val_accuracy: 0.7982\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 9s 393ms/step - loss: 0.0617 - accuracy: 0.9868 - val_loss: 1.2078 - val_accuracy: 0.7982\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 9s 396ms/step - loss: 0.0620 - accuracy: 0.9868 - val_loss: 1.2332 - val_accuracy: 0.7982\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0577 - accuracy: 0.9868 - val_loss: 1.2848 - val_accuracy: 0.7939\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 9s 396ms/step - loss: 0.0559 - accuracy: 0.9868 - val_loss: 1.3570 - val_accuracy: 0.7982\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0581 - accuracy: 0.9883 - val_loss: 1.2703 - val_accuracy: 0.7895\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0511 - accuracy: 0.9883 - val_loss: 1.3933 - val_accuracy: 0.7982\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0555 - accuracy: 0.9868 - val_loss: 1.4025 - val_accuracy: 0.7939\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 8s 385ms/step - loss: 0.0945 - accuracy: 0.9780 - val_loss: 1.2066 - val_accuracy: 0.7807\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 9s 390ms/step - loss: 0.0937 - accuracy: 0.9678 - val_loss: 1.0893 - val_accuracy: 0.7939\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0815 - accuracy: 0.9751 - val_loss: 1.1104 - val_accuracy: 0.8114\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 9s 416ms/step - loss: 0.0558 - accuracy: 0.9883 - val_loss: 1.2210 - val_accuracy: 0.7982\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0579 - accuracy: 0.9883 - val_loss: 1.1926 - val_accuracy: 0.8026\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 9s 415ms/step - loss: 0.0517 - accuracy: 0.9883 - val_loss: 1.3273 - val_accuracy: 0.8026\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0589 - accuracy: 0.9883 - val_loss: 1.2817 - val_accuracy: 0.8026\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0577 - accuracy: 0.9883 - val_loss: 1.2716 - val_accuracy: 0.8070\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0522 - accuracy: 0.9883 - val_loss: 1.3195 - val_accuracy: 0.8026\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0583 - accuracy: 0.9883 - val_loss: 1.3832 - val_accuracy: 0.8026\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 1.4103 - val_accuracy: 0.8026\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0530 - accuracy: 0.9883 - val_loss: 1.4512 - val_accuracy: 0.7982\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 9s 389ms/step - loss: 0.0503 - accuracy: 0.9883 - val_loss: 1.4538 - val_accuracy: 0.7982\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0472 - accuracy: 0.9883 - val_loss: 1.5853 - val_accuracy: 0.7982\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 10s 454ms/step - loss: 0.0501 - accuracy: 0.9883 - val_loss: 1.5589 - val_accuracy: 0.7982\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0448 - accuracy: 0.9883 - val_loss: 1.5908 - val_accuracy: 0.7982\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 1.4579 - val_accuracy: 0.7982\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0489 - accuracy: 0.9883 - val_loss: 1.5490 - val_accuracy: 0.7982\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 1.5934 - val_accuracy: 0.7982\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 9s 419ms/step - loss: 0.0483 - accuracy: 0.9883 - val_loss: 1.7041 - val_accuracy: 0.7982\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0483 - accuracy: 0.9883 - val_loss: 1.7420 - val_accuracy: 0.7982\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0499 - accuracy: 0.9883 - val_loss: 1.7428 - val_accuracy: 0.7982\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 9s 415ms/step - loss: 0.0443 - accuracy: 0.9883 - val_loss: 1.7219 - val_accuracy: 0.7939\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0440 - accuracy: 0.9883 - val_loss: 1.7786 - val_accuracy: 0.7939\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 1.6780 - val_accuracy: 0.7982\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 10s 439ms/step - loss: 0.0515 - accuracy: 0.9868 - val_loss: 1.6859 - val_accuracy: 0.7895\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0459 - accuracy: 0.9868 - val_loss: 1.6167 - val_accuracy: 0.7895\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 1.6406 - val_accuracy: 0.7939\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 10s 438ms/step - loss: 0.0561 - accuracy: 0.9839 - val_loss: 1.4489 - val_accuracy: 0.8070\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0835 - accuracy: 0.9736 - val_loss: 1.1493 - val_accuracy: 0.7939\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 9s 418ms/step - loss: 0.0597 - accuracy: 0.9868 - val_loss: 1.3385 - val_accuracy: 0.7939\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0547 - accuracy: 0.9868 - val_loss: 1.3953 - val_accuracy: 0.7939\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 1.4829 - val_accuracy: 0.7982\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0500 - accuracy: 0.9883 - val_loss: 1.4819 - val_accuracy: 0.7982\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 9s 413ms/step - loss: 0.0495 - accuracy: 0.9883 - val_loss: 1.5889 - val_accuracy: 0.7982\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 9s 419ms/step - loss: 0.0425 - accuracy: 0.9883 - val_loss: 1.5615 - val_accuracy: 0.7982\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0546 - accuracy: 0.9883 - val_loss: 1.5544 - val_accuracy: 0.7982\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 1.4775 - val_accuracy: 0.8026\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 1.4790 - val_accuracy: 0.7982\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0534 - accuracy: 0.9883 - val_loss: 1.4496 - val_accuracy: 0.7982\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0470 - accuracy: 0.9883 - val_loss: 1.3959 - val_accuracy: 0.8026\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 1.4115 - val_accuracy: 0.7939\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0492 - accuracy: 0.9883 - val_loss: 1.4899 - val_accuracy: 0.7982\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0428 - accuracy: 0.9883 - val_loss: 1.5980 - val_accuracy: 0.7939\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0431 - accuracy: 0.9883 - val_loss: 1.6050 - val_accuracy: 0.7939\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 9s 413ms/step - loss: 0.0451 - accuracy: 0.9883 - val_loss: 1.7062 - val_accuracy: 0.7851\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0561 - accuracy: 0.9883 - val_loss: 1.7305 - val_accuracy: 0.7982\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 1.6519 - val_accuracy: 0.7982\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0680 - accuracy: 0.9839 - val_loss: 1.4427 - val_accuracy: 0.7939\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 1.3112 - val_accuracy: 0.7939\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 9s 418ms/step - loss: 0.0446 - accuracy: 0.9883 - val_loss: 1.4133 - val_accuracy: 0.7939\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 1.5257 - val_accuracy: 0.7939\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 9s 394ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: 1.4801 - val_accuracy: 0.7851\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 1.5330 - val_accuracy: 0.7851\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0429 - accuracy: 0.9898 - val_loss: 1.5250 - val_accuracy: 0.7851\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 9s 397ms/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 1.3614 - val_accuracy: 0.7807\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 1.4945 - val_accuracy: 0.7763\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 9s 399ms/step - loss: 0.0397 - accuracy: 0.9898 - val_loss: 1.5923 - val_accuracy: 0.7807\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0430 - accuracy: 0.9810 - val_loss: 1.6213 - val_accuracy: 0.7895\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 9s 394ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 1.6606 - val_accuracy: 0.7895\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 1.7172 - val_accuracy: 0.7851\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 1.6346 - val_accuracy: 0.7851\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0428 - accuracy: 0.9912 - val_loss: 1.6731 - val_accuracy: 0.7807\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 1.6637 - val_accuracy: 0.7807\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.0384 - accuracy: 0.9912 - val_loss: 1.6780 - val_accuracy: 0.7807\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 1.7859 - val_accuracy: 0.7851\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 1.7862 - val_accuracy: 0.7807\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 1.8000 - val_accuracy: 0.7763\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 1.8794 - val_accuracy: 0.7807\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 1.8237 - val_accuracy: 0.7719\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 1.8416 - val_accuracy: 0.7763\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 1.8666 - val_accuracy: 0.7763\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 1.9205 - val_accuracy: 0.7851\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 9s 400ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 1.8440 - val_accuracy: 0.7851\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 9s 400ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 1.8498 - val_accuracy: 0.7807\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 9s 397ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 1.8814 - val_accuracy: 0.7807\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 1.9306 - val_accuracy: 0.7851\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0376 - accuracy: 0.9898 - val_loss: 1.8468 - val_accuracy: 0.7895\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 9s 398ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 1.7717 - val_accuracy: 0.7895\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 1.8582 - val_accuracy: 0.7851\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 1.9115 - val_accuracy: 0.7895\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 9s 399ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 1.8889 - val_accuracy: 0.7895\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 1.9309 - val_accuracy: 0.7895\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 1.9626 - val_accuracy: 0.7895\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 9s 395ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 1.9373 - val_accuracy: 0.7851\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 9s 398ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 1.9148 - val_accuracy: 0.7895\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 1.9228 - val_accuracy: 0.7851\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0361 - accuracy: 0.9912 - val_loss: 1.9849 - val_accuracy: 0.7807\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0390 - accuracy: 0.9912 - val_loss: 1.9388 - val_accuracy: 0.7807\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 1.9471 - val_accuracy: 0.7763\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0347 - accuracy: 0.9898 - val_loss: 1.9488 - val_accuracy: 0.7851\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 2.0688 - val_accuracy: 0.7851\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 1.9831 - val_accuracy: 0.7851\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 1.9881 - val_accuracy: 0.7763\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 2.0513 - val_accuracy: 0.7807\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 2.0686 - val_accuracy: 0.7895\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0449 - accuracy: 0.9912 - val_loss: 1.8367 - val_accuracy: 0.7807\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 1.7163 - val_accuracy: 0.7763\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0518 - accuracy: 0.9854 - val_loss: 1.3442 - val_accuracy: 0.7807\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0814 - accuracy: 0.9780 - val_loss: 1.3432 - val_accuracy: 0.7763\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0579 - accuracy: 0.9854 - val_loss: 1.4589 - val_accuracy: 0.7719\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 9s 418ms/step - loss: 0.0562 - accuracy: 0.9839 - val_loss: 1.5072 - val_accuracy: 0.7763\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0584 - accuracy: 0.9854 - val_loss: 1.5849 - val_accuracy: 0.7719\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0447 - accuracy: 0.9883 - val_loss: 1.4591 - val_accuracy: 0.7675\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 10s 443ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 1.5676 - val_accuracy: 0.7719\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 1.6956 - val_accuracy: 0.7763\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 1.6666 - val_accuracy: 0.7719\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0357 - accuracy: 0.9898 - val_loss: 1.6646 - val_accuracy: 0.7719\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 1.6799 - val_accuracy: 0.7675\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 9s 421ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 1.7087 - val_accuracy: 0.7719\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 1.7099 - val_accuracy: 0.7675\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 1.7527 - val_accuracy: 0.7632\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 1.8234 - val_accuracy: 0.7675\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.0369 - accuracy: 0.9898 - val_loss: 1.7766 - val_accuracy: 0.7719\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 1.7519 - val_accuracy: 0.7719\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 9s 400ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 1.7896 - val_accuracy: 0.7763\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 9s 400ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 1.8435 - val_accuracy: 0.7763\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 1.8467 - val_accuracy: 0.7763\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 9s 418ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 1.8912 - val_accuracy: 0.7763\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0360 - accuracy: 0.9898 - val_loss: 1.8938 - val_accuracy: 0.7719\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0399 - accuracy: 0.9898 - val_loss: 1.8557 - val_accuracy: 0.7675\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 1.9157 - val_accuracy: 0.7719\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 1.8647 - val_accuracy: 0.7719\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 1.9569 - val_accuracy: 0.7719\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 1.9886 - val_accuracy: 0.7719\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 2.0081 - val_accuracy: 0.7632\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 2.0679 - val_accuracy: 0.7675\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 2.0469 - val_accuracy: 0.7632\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 2.0752 - val_accuracy: 0.7675\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 9s 414ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 2.0987 - val_accuracy: 0.7675\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 2.0088 - val_accuracy: 0.7632\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 2.1200 - val_accuracy: 0.7675\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 10s 433ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 2.0980 - val_accuracy: 0.7675\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 2.1679 - val_accuracy: 0.7675\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 2.0826 - val_accuracy: 0.7719\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 2.1127 - val_accuracy: 0.7719\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 2.0906 - val_accuracy: 0.7675\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0370 - accuracy: 0.9927 - val_loss: 2.0931 - val_accuracy: 0.7675\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 2.1886 - val_accuracy: 0.7675\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0376 - accuracy: 0.9912 - val_loss: 2.1108 - val_accuracy: 0.7632\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 1.8885 - val_accuracy: 0.7895\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.1373 - accuracy: 0.9590 - val_loss: 0.9268 - val_accuracy: 0.7632\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.0601 - accuracy: 0.9854 - val_loss: 1.0023 - val_accuracy: 0.7982\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0557 - accuracy: 0.9883 - val_loss: 1.0762 - val_accuracy: 0.7982\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: 1.0929 - val_accuracy: 0.7982\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 9s 399ms/step - loss: 0.0459 - accuracy: 0.9883 - val_loss: 1.1374 - val_accuracy: 0.7982\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 9s 405ms/step - loss: 0.0484 - accuracy: 0.9883 - val_loss: 1.1529 - val_accuracy: 0.7895\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.0421 - accuracy: 0.9898 - val_loss: 1.2178 - val_accuracy: 0.7982\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 1.2567 - val_accuracy: 0.7851\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 1.2195 - val_accuracy: 0.7851\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 1.2435 - val_accuracy: 0.7851\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 10s 448ms/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 1.2241 - val_accuracy: 0.7807\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 1.3011 - val_accuracy: 0.7851\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 1.2755 - val_accuracy: 0.7851\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0413 - accuracy: 0.9883 - val_loss: 1.3218 - val_accuracy: 0.7851\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0398 - accuracy: 0.9912 - val_loss: 1.3165 - val_accuracy: 0.7851\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 10s 441ms/step - loss: 0.0398 - accuracy: 0.9912 - val_loss: 1.3424 - val_accuracy: 0.7895\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0427 - accuracy: 0.9883 - val_loss: 1.3623 - val_accuracy: 0.7807\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 1.3545 - val_accuracy: 0.7895\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 10s 439ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 1.4008 - val_accuracy: 0.7851\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 1.4318 - val_accuracy: 0.7807\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 1.5123 - val_accuracy: 0.7456\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0489 - accuracy: 0.9839 - val_loss: 1.3593 - val_accuracy: 0.7807\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0369 - accuracy: 0.9898 - val_loss: 1.5107 - val_accuracy: 0.7807\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0316 - accuracy: 0.9927 - val_loss: 1.5975 - val_accuracy: 0.7807\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0399 - accuracy: 0.9898 - val_loss: 1.5227 - val_accuracy: 0.7763\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 0.0400 - accuracy: 0.9898 - val_loss: 1.4859 - val_accuracy: 0.7807\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 1.5103 - val_accuracy: 0.7807\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 9s 416ms/step - loss: 0.0383 - accuracy: 0.9927 - val_loss: 1.4951 - val_accuracy: 0.7807\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 1.5471 - val_accuracy: 0.7807\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 9s 415ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 1.5721 - val_accuracy: 0.7807\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 1.6196 - val_accuracy: 0.7807\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 9s 415ms/step - loss: 0.0387 - accuracy: 0.9912 - val_loss: 1.6080 - val_accuracy: 0.7807\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 1.6039 - val_accuracy: 0.7807\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 1.6025 - val_accuracy: 0.7851\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 9s 421ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 1.5538 - val_accuracy: 0.7807\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 1.6307 - val_accuracy: 0.7851\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 1.6046 - val_accuracy: 0.7851\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0378 - accuracy: 0.9898 - val_loss: 1.6627 - val_accuracy: 0.7807\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 10s 449ms/step - loss: 0.0360 - accuracy: 0.9927 - val_loss: 1.6621 - val_accuracy: 0.7851\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 1.6860 - val_accuracy: 0.7851\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 1.6906 - val_accuracy: 0.7807\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 1.6870 - val_accuracy: 0.7807\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 10s 436ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 1.7213 - val_accuracy: 0.7851\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 10s 445ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 1.7766 - val_accuracy: 0.7807\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 10s 434ms/step - loss: 0.0338 - accuracy: 0.9927 - val_loss: 1.7240 - val_accuracy: 0.7807\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 1.7113 - val_accuracy: 0.7763\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0382 - accuracy: 0.9927 - val_loss: 1.7302 - val_accuracy: 0.7807\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0377 - accuracy: 0.9898 - val_loss: 1.7187 - val_accuracy: 0.7807\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 1.7254 - val_accuracy: 0.7807\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 9s 421ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 1.7545 - val_accuracy: 0.7807\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 9s 411ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 1.7515 - val_accuracy: 0.7763\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 9s 431ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 1.8203 - val_accuracy: 0.7807\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 10s 436ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 1.8118 - val_accuracy: 0.7719\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 10s 470ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 1.7671 - val_accuracy: 0.7763\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 1.8520 - val_accuracy: 0.7719\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 10s 446ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 1.8390 - val_accuracy: 0.7675\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 12s 528ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 1.8169 - val_accuracy: 0.7675\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 12s 522ms/step - loss: 0.0335 - accuracy: 0.9927 - val_loss: 1.8603 - val_accuracy: 0.7675\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 1.8881 - val_accuracy: 0.7675\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 10s 444ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 1.8842 - val_accuracy: 0.7632\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 15s 676ms/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 1.8625 - val_accuracy: 0.7675\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 13s 608ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 1.8780 - val_accuracy: 0.7719\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 15s 663ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 1.9091 - val_accuracy: 0.7632\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0384 - accuracy: 0.9927 - val_loss: 1.8881 - val_accuracy: 0.7632\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 9s 416ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 1.9420 - val_accuracy: 0.7675\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 1.9783 - val_accuracy: 0.7632\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0325 - accuracy: 0.9927 - val_loss: 2.0416 - val_accuracy: 0.7632\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 1.9904 - val_accuracy: 0.7632\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 9s 413ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 2.0113 - val_accuracy: 0.7632\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0339 - accuracy: 0.9927 - val_loss: 1.9902 - val_accuracy: 0.7632\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 9s 413ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 1.9980 - val_accuracy: 0.7675\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 10s 437ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 2.0685 - val_accuracy: 0.7588\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0303 - accuracy: 0.9927 - val_loss: 2.0409 - val_accuracy: 0.7588\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 10s 449ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 2.0474 - val_accuracy: 0.7588\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 10s 447ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 2.0838 - val_accuracy: 0.7588\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 10s 464ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 2.0428 - val_accuracy: 0.7675\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 2.0862 - val_accuracy: 0.7719\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0334 - accuracy: 0.9927 - val_loss: 2.0365 - val_accuracy: 0.7588\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 11s 493ms/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 2.0891 - val_accuracy: 0.7632\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 10s 433ms/step - loss: 0.0346 - accuracy: 0.9927 - val_loss: 1.9960 - val_accuracy: 0.7675\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 11s 483ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 2.0013 - val_accuracy: 0.7632\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 10s 465ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 2.0228 - val_accuracy: 0.7632\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 10s 454ms/step - loss: 0.0329 - accuracy: 0.9927 - val_loss: 2.0779 - val_accuracy: 0.7632\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 9s 429ms/step - loss: 0.0334 - accuracy: 0.9927 - val_loss: 2.0296 - val_accuracy: 0.7632\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0339 - accuracy: 0.9927 - val_loss: 2.0371 - val_accuracy: 0.7675\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 2.0290 - val_accuracy: 0.7632\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0400 - accuracy: 0.9912 - val_loss: 2.1093 - val_accuracy: 0.7588\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 2.0907 - val_accuracy: 0.7632\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.0334 - accuracy: 0.9927 - val_loss: 2.0973 - val_accuracy: 0.7632\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0308 - accuracy: 0.9927 - val_loss: 2.1231 - val_accuracy: 0.7632\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.0319 - accuracy: 0.9927 - val_loss: 2.1856 - val_accuracy: 0.7632\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 2.1089 - val_accuracy: 0.7675\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0335 - accuracy: 0.9927 - val_loss: 2.1516 - val_accuracy: 0.7632\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.0342 - accuracy: 0.9927 - val_loss: 2.1766 - val_accuracy: 0.7632\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0333 - accuracy: 0.9927 - val_loss: 2.0855 - val_accuracy: 0.7675\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 9s 415ms/step - loss: 0.0339 - accuracy: 0.9927 - val_loss: 2.2049 - val_accuracy: 0.7632\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 9s 419ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 2.1701 - val_accuracy: 0.7632\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0309 - accuracy: 0.9927 - val_loss: 2.1891 - val_accuracy: 0.7719\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 9s 409ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 2.1444 - val_accuracy: 0.7632\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 9s 416ms/step - loss: 0.0348 - accuracy: 0.9927 - val_loss: 2.1765 - val_accuracy: 0.7719\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 10s 434ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 2.1916 - val_accuracy: 0.7675\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 9s 431ms/step - loss: 0.0334 - accuracy: 0.9927 - val_loss: 2.1879 - val_accuracy: 0.7719\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 9s 410ms/step - loss: 0.0330 - accuracy: 0.9927 - val_loss: 2.1762 - val_accuracy: 0.7632\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0335 - accuracy: 0.9927 - val_loss: 2.2268 - val_accuracy: 0.7675\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.0329 - accuracy: 0.9927 - val_loss: 2.2413 - val_accuracy: 0.7632\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 9s 408ms/step - loss: 0.0329 - accuracy: 0.9927 - val_loss: 2.1074 - val_accuracy: 0.7632\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0328 - accuracy: 0.9927 - val_loss: 2.2076 - val_accuracy: 0.7632\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.0327 - accuracy: 0.9927 - val_loss: 2.2392 - val_accuracy: 0.7632\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 9s 421ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 2.2254 - val_accuracy: 0.7588\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 2.2036 - val_accuracy: 0.7675\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 2.2265 - val_accuracy: 0.7632\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 10s 438ms/step - loss: 0.0306 - accuracy: 0.9927 - val_loss: 2.2851 - val_accuracy: 0.7632\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 10s 441ms/step - loss: 0.0318 - accuracy: 0.9927 - val_loss: 2.3253 - val_accuracy: 0.7632\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 2.3017 - val_accuracy: 0.7544\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 9s 415ms/step - loss: 0.0301 - accuracy: 0.9927 - val_loss: 2.2861 - val_accuracy: 0.7544\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 2.2710 - val_accuracy: 0.7588\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0345 - accuracy: 0.9927 - val_loss: 2.3151 - val_accuracy: 0.7632\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 10s 450ms/step - loss: 0.0315 - accuracy: 0.9927 - val_loss: 2.1583 - val_accuracy: 0.7325\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0317 - accuracy: 0.9927 - val_loss: 2.2583 - val_accuracy: 0.7675\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 10s 434ms/step - loss: 0.0342 - accuracy: 0.9927 - val_loss: 2.2533 - val_accuracy: 0.7675\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 10s 442ms/step - loss: 0.0329 - accuracy: 0.9927 - val_loss: 2.3410 - val_accuracy: 0.7675\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 10s 439ms/step - loss: 0.0311 - accuracy: 0.9927 - val_loss: 2.3119 - val_accuracy: 0.7675\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 10s 451ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 2.3370 - val_accuracy: 0.7632\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 10s 448ms/step - loss: 0.0333 - accuracy: 0.9927 - val_loss: 2.2578 - val_accuracy: 0.7719\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 10s 444ms/step - loss: 0.0311 - accuracy: 0.9927 - val_loss: 2.2798 - val_accuracy: 0.7675\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 10s 438ms/step - loss: 0.0267 - accuracy: 0.9927 - val_loss: 2.3039 - val_accuracy: 0.7719\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 2.3342 - val_accuracy: 0.7675\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 9s 425ms/step - loss: 0.0343 - accuracy: 0.9927 - val_loss: 2.3464 - val_accuracy: 0.7675\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 10s 452ms/step - loss: 0.0313 - accuracy: 0.9927 - val_loss: 2.3561 - val_accuracy: 0.7675\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 10s 449ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 2.4137 - val_accuracy: 0.7632\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0340 - accuracy: 0.9927 - val_loss: 2.2954 - val_accuracy: 0.7632\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 2.3785 - val_accuracy: 0.7632\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 10s 436ms/step - loss: 0.0303 - accuracy: 0.9927 - val_loss: 2.3579 - val_accuracy: 0.7632\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 10s 441ms/step - loss: 0.0298 - accuracy: 0.9927 - val_loss: 2.3756 - val_accuracy: 0.7675\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 9s 417ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 2.3819 - val_accuracy: 0.7632\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0331 - accuracy: 0.9927 - val_loss: 2.3670 - val_accuracy: 0.7588\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 10s 449ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 2.2660 - val_accuracy: 0.7588\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 10s 445ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 1.6476 - val_accuracy: 0.7763\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 10s 440ms/step - loss: 0.0712 - accuracy: 0.9780 - val_loss: 1.4563 - val_accuracy: 0.7675\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0496 - accuracy: 0.9883 - val_loss: 1.5871 - val_accuracy: 0.7807\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: 1.7782 - val_accuracy: 0.7763\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 10s 441ms/step - loss: 0.0552 - accuracy: 0.9868 - val_loss: 1.7801 - val_accuracy: 0.7368\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 10s 445ms/step - loss: 0.0648 - accuracy: 0.9883 - val_loss: 2.1846 - val_accuracy: 0.7807\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 10s 446ms/step - loss: 0.0470 - accuracy: 0.9898 - val_loss: 1.8519 - val_accuracy: 0.7807\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 10s 469ms/step - loss: 0.0377 - accuracy: 0.9898 - val_loss: 1.9813 - val_accuracy: 0.7807\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 2.0329 - val_accuracy: 0.7763\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 10s 444ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 2.1501 - val_accuracy: 0.7763\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 10s 441ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 2.1010 - val_accuracy: 0.7763\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 2.1345 - val_accuracy: 0.7763\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 2.3138 - val_accuracy: 0.7675\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 10s 442ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 2.1651 - val_accuracy: 0.7719\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 2.3090 - val_accuracy: 0.7675\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 10s 457ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 2.3063 - val_accuracy: 0.7675\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 10s 454ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 2.2400 - val_accuracy: 0.7763\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 10s 468ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 2.2554 - val_accuracy: 0.7675\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 9s 431ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 2.3427 - val_accuracy: 0.7675\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 10s 456ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 2.3342 - val_accuracy: 0.7719\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 11s 484ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 2.3616 - val_accuracy: 0.7675\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 10s 446ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 2.4522 - val_accuracy: 0.7719\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 10s 442ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 2.3006 - val_accuracy: 0.7588\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 10s 449ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 2.3331 - val_accuracy: 0.7632\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 10s 441ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 2.4272 - val_accuracy: 0.7719\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 10s 461ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 2.4499 - val_accuracy: 0.7632\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 10s 460ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 2.3847 - val_accuracy: 0.7632\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 10s 430ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 2.4154 - val_accuracy: 0.7588\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 2.4798 - val_accuracy: 0.7588\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 2.4093 - val_accuracy: 0.7588\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 2.4837 - val_accuracy: 0.7763\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 10s 437ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 2.4053 - val_accuracy: 0.7588\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 10s 455ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 2.4792 - val_accuracy: 0.7719\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 10s 437ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 2.4118 - val_accuracy: 0.7588\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 2.4846 - val_accuracy: 0.7632\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 10s 444ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 2.4706 - val_accuracy: 0.7632\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 10s 437ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 2.4793 - val_accuracy: 0.7719\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 2.5484 - val_accuracy: 0.7763\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 2.4965 - val_accuracy: 0.7675\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 2.5666 - val_accuracy: 0.7763\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 10s 435ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 2.4402 - val_accuracy: 0.7675\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 9s 423ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 2.5359 - val_accuracy: 0.7675\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 10s 433ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 2.5004 - val_accuracy: 0.7632\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 9s 431ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 2.4847 - val_accuracy: 0.7632\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 10s 433ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 2.4870 - val_accuracy: 0.7632\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 2.4842 - val_accuracy: 0.7588\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 2.5513 - val_accuracy: 0.7675\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 10s 434ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 2.5142 - val_accuracy: 0.7719\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 2.5838 - val_accuracy: 0.7632\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 9s 428ms/step - loss: 0.0352 - accuracy: 0.9912 - val_loss: 2.4846 - val_accuracy: 0.7675\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 2.5237 - val_accuracy: 0.7632\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 10s 432ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 2.5170 - val_accuracy: 0.7632\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 2.5348 - val_accuracy: 0.7632\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 9s 422ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 2.5257 - val_accuracy: 0.7675\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 9s 427ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 2.5693 - val_accuracy: 0.7632\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 9s 420ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 2.5804 - val_accuracy: 0.7632\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 9s 430ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 2.5795 - val_accuracy: 0.7632\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 9s 432ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 2.5641 - val_accuracy: 0.7632\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 10s 434ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 2.6085 - val_accuracy: 0.7632\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 10s 433ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 2.5716 - val_accuracy: 0.7632\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 10s 434ms/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 2.6066 - val_accuracy: 0.7632\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 10s 437ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 2.5967 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d06422af0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=500,validation_data=(X_test, y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc1fe1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key difference between GRU and LSTM is that GRU's bag has two gates that are reset and update while\n",
    "# LSTM has three gates that are input, output, forget. GRU is less complex than LSTM because it has less number of gates.\n",
    "# If the dataset is small then GRU is preferred otherwise LSTM for the larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16036cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b865878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Supporter=[]\n",
    "for i in prediction:\n",
    "    if i>=0.5:\n",
    "        Supporter.append(\"Salman Khan\")\n",
    "    else:\n",
    "        Supporter.append(\"Shahrukh Khan\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3ea2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shahrukh Khan',\n",
       " 'Shahrukh Khan',\n",
       " 'Salman Khan',\n",
       " 'Salman Khan',\n",
       " 'Shahrukh Khan',\n",
       " 'Salman Khan',\n",
       " 'Salman Khan',\n",
       " 'Shahrukh Khan',\n",
       " 'Shahrukh Khan',\n",
       " 'Salman Khan',\n",
       " 'Shahrukh Khan',\n",
       " 'Salman Khan']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Supporter[3:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "244849b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3                Bollywood ka sabse bada super star srk\n",
       "4     In India Salman Khan has bigger stardom than S...\n",
       "5                                                 Sallu\n",
       "6                                           Srk is king\n",
       "7                 Salman living in people&#39;s heart ❤\n",
       "8                    Ladko ka favourite only sallu bhai\n",
       "9            Salman bhai bus aur koi nhi hai un ke siva\n",
       "10    Salman Khan ko hi King Khan hona hai srk bakwa...\n",
       "11            Only bhaijan kyoki he has a pure heart 🥰🥰\n",
       "12               Salman Khan is best hero for bollywood\n",
       "13                                        Shahrukh Khan\n",
       "14                          One n only Salman Khan bhai\n",
       "Name: Comment, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Comment\"][3:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04f68f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write your review about your favourite supporter\n",
      "King Khan\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Shahrukh Khan Supporter\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "data=[input(\"Write your review about your favourite supporter\\n\")]\n",
    "# Generate and pad the training sequences\n",
    "sequencesp = tokenizer.texts_to_sequences(data)\n",
    "paddedp = pad_sequences(sequencesp,maxlen=max_length, truncating=trunc_type)\n",
    "prediction=model.predict(paddedp)\n",
    "if prediction>0.5:\n",
    "    print(\"Shahrukh Khan Supporter\")\n",
    "    \n",
    "else:\n",
    "    print(\"Salman Khan Supporter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2353e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
